{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot use cuda accelerate\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import dask as da\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.ndimage import label, gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "# MINIAN_PATH = \"./minian_snapshot\"\n",
    "# sys.path.append(MINIAN_PATH)\n",
    "\n",
    "# from minian.utilities import open_minian\n",
    "from minian_snapshot.minian.utilities import open_minian, xrconcat_recursive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ts(ts: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"map frames from Cam1 to Cam0 with nearest neighbour using the timestamp file from miniscope recordings.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : pd.DataFrame\n",
    "        input timestamp dataframe. should contain field 'frameNum', 'camNum' and 'sysClock'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        output dataframe. should contain field 'fmCam0' and 'fmCam1'\n",
    "    \"\"\"\n",
    "    ts_sort = ts.sort_values(\"sysClock\")\n",
    "    ts_sort[\"ts_behav\"] = np.where(ts_sort[\"camNum\"] == 1, ts_sort[\"sysClock\"], np.nan)\n",
    "    ts_sort[\"ts_forward\"] = ts_sort[\"ts_behav\"].fillna(method=\"ffill\")\n",
    "    ts_sort[\"ts_backward\"] = ts_sort[\"ts_behav\"].fillna(method=\"bfill\")\n",
    "    ts_sort[\"diff_forward\"] = np.absolute(ts_sort[\"sysClock\"] - ts_sort[\"ts_forward\"])\n",
    "    ts_sort[\"diff_backward\"] = np.absolute(ts_sort[\"sysClock\"] - ts_sort[\"ts_backward\"])\n",
    "    ts_sort[\"fm_behav\"] = np.where(ts_sort[\"camNum\"] == 1, ts_sort[\"frameNum\"], np.nan)\n",
    "    ts_sort[\"fm_forward\"] = ts_sort[\"fm_behav\"].fillna(method=\"ffill\")\n",
    "    ts_sort[\"fm_backward\"] = ts_sort[\"fm_behav\"].fillna(method=\"bfill\")\n",
    "    ts_sort[\"fmCam1\"] = np.where(\n",
    "        ts_sort[\"diff_forward\"] < ts_sort[\"diff_backward\"],\n",
    "        ts_sort[\"fm_forward\"],\n",
    "        ts_sort[\"fm_backward\"],\n",
    "    )\n",
    "    ts_map = (\n",
    "        ts_sort[ts_sort[\"camNum\"] == 0][[\"frameNum\", \"fmCam1\"]]\n",
    "        .dropna()\n",
    "        .rename(columns=dict(frameNum=\"fmCam0\"))\n",
    "        .astype(dict(fmCam1=int))\n",
    "    )\n",
    "    ts_map[\"fmCam0\"] = ts_map[\"fmCam0\"] - 1\n",
    "    ts_map[\"fmCam1\"] = ts_map[\"fmCam1\"] - 1\n",
    "    return ts_map\n",
    "\n",
    "\n",
    "def process_behav(\n",
    "    behav: pd.DataFrame, run_dim=\"X\", wnd=31, thres_dx=0.05, thres_rw=20,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"differntiate locations based on running directions,\n",
    "    and filter out frames when the animal is not moving.\n",
    "    The output locaion will have the same sign as running speed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    behav : pd.DataFrame\n",
    "        input dataframe of behavior tracking results, should contain a column with name `run_dim`.\n",
    "    run_dim : str, optional\n",
    "        the dimension along which the animal is running, by default \"X\"\n",
    "    wnd : int, optional\n",
    "        the window size in frames where the running speed is estimated and media-filtered, by default 31\n",
    "    thres_dx : float, optional\n",
    "        the threshold for change of pixel per frame along `run_dim`, below which all the frames will be discarded, by default 0.01\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        output dataframe\n",
    "    \"\"\"\n",
    "    behav[\"dx\"] = medfilt(np.gradient(behav[run_dim], wnd), wnd)\n",
    "    behav[\"stationary\"] = thres_gmm(np.abs(behav[\"dx\"]).values, com=0)\n",
    "    xmax, xmin = behav[\"X\"].max() - thres_rw, behav[\"X\"].min() + thres_rw\n",
    "    behav[\"reward_zone\"] = ~behav[\"X\"].between(xmin, xmax)\n",
    "    rw_low = (behav[\"X\"] < xmin).astype(int)\n",
    "    rw_high = (behav[\"X\"] > xmax).astype(int)\n",
    "    trans_low = [(t, \"low\") for t in np.where(rw_low.diff() == -1)[0]]\n",
    "    trans_high = [(t, \"high\") for t in np.where(rw_high.diff() == -1)[0]]\n",
    "    trans = (\n",
    "        pd.DataFrame(trans_low + trans_high, columns=(\"index\", \"reward\"))\n",
    "        .sort_values(\"index\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    if trans.iloc[0][\"reward\"] == \"low\":\n",
    "        trans[\"r\"] = trans[\"reward\"].map({\"low\": 1, \"high\": 0})\n",
    "    else:\n",
    "        trans[\"r\"] = trans[\"reward\"].map({\"low\": 0, \"high\": 1})\n",
    "    trans = trans[trans[\"r\"].diff().fillna(1) == 1]\n",
    "    behav[\"trial\"] = 0\n",
    "    behav.loc[trans[\"index\"], \"trial\"] = 1\n",
    "    behav[\"trial\"] = behav[\"trial\"].cumsum().astype(int)\n",
    "    dx_sign = np.sign(behav[\"dx\"])\n",
    "    behav[run_dim] = behav[run_dim] * dx_sign\n",
    "    behav = behav[(~behav[\"stationary\"]) & (~behav[\"reward_zone\"])]\n",
    "    return behav\n",
    "\n",
    "\n",
    "def norm(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"normalize input array to the range of [0, 1]. Can handle Nan and zero range.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : np.ndarray\n",
    "        input array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        normalized array.\n",
    "    \"\"\"\n",
    "    amin = np.nanmin(a)\n",
    "    return (a - amin) / (np.nanmax(a) - amin + np.finfo(float).eps)\n",
    "\n",
    "\n",
    "def gaussian_nan(a, **kwargs):\n",
    "    nan_mask = np.isnan(a)\n",
    "    v = np.nan_to_num(a)\n",
    "    w = np.where(nan_mask, 0, 1).astype(np.float)\n",
    "    ag = gaussian_filter1d(v, **kwargs) / gaussian_filter1d(w, **kwargs)\n",
    "    return np.where(nan_mask, np.nan, ag)\n",
    "\n",
    "\n",
    "def compute_fr(\n",
    "    S: xr.DataArray, bin_dim=\"x\", nbins=100, normalize=True, sigma=2.5\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"compute averaged firing rate by binning along the 'frame' dimension according to `bin_dim`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : xr.DataArray\n",
    "        input data representing raw spikes. presumably the S matrix from CNMF\n",
    "    bin_dim : str, optional\n",
    "        the dimension according to which the spikes are binned and averaged, by default 'x'\n",
    "    nbins : int, optional\n",
    "        number of bins, by default 100\n",
    "    normalize : bool, optional\n",
    "        whether to normalize result, by default True\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        output firing rate\n",
    "    \"\"\"\n",
    "    bdim = bin_dim + \"_bins\"\n",
    "    fr = S.groupby_bins(bin_dim, nbins).mean(dim=\"frame\")\n",
    "    fr = fr.assign_coords({bdim: np.arange(fr.sizes[bdim])}).rename(\"fr\")\n",
    "    if normalize:\n",
    "        fr = xr.apply_ufunc(\n",
    "            norm,\n",
    "            fr.chunk({bdim: -1}),\n",
    "            input_core_dims=[[bdim]],\n",
    "            output_core_dims=[[bdim]],\n",
    "            vectorize=True,\n",
    "            dask=\"parallelized\",\n",
    "            output_dtypes=[fr.dtype],\n",
    "        )\n",
    "    if sigma is not None:\n",
    "        fr = xr.apply_ufunc(\n",
    "            gaussian_nan,\n",
    "            fr.chunk({bdim: -1}),\n",
    "            input_core_dims=[[bdim]],\n",
    "            output_core_dims=[[bdim]],\n",
    "            vectorize=True,\n",
    "            kwargs={\"sigma\": sigma},\n",
    "            dask=\"parallelized\",\n",
    "            output_dtypes=[fr.dtype],\n",
    "        )\n",
    "    return fr\n",
    "\n",
    "\n",
    "def compute_occp(S: xr.DataArray, bin_dim=\"x\", nbins=100, sigma=2.5) -> xr.DataArray:\n",
    "    \"\"\"calculate the occupancy based on count of frames in each bin according to `bin_dim`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : xr.DataArray\n",
    "        input data representing raw spikes. presumably the S matrix from CNMF\n",
    "    bin_dim : str, optional\n",
    "        the dimension according to which frames are counted, by default 'x'\n",
    "    nbins : int, optional\n",
    "        number of bins, by default 100\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        output occupancy array\n",
    "    \"\"\"\n",
    "    bdim = bin_dim + \"_bins\"\n",
    "    occp = S[bin_dim].groupby_bins(bin_dim, nbins).count() / S[bin_dim].count()\n",
    "    occp = occp.assign_coords({bdim: np.arange(occp.sizes[bdim])}).rename(\"occp\")\n",
    "    if sigma is not None:\n",
    "        occp = xr.apply_ufunc(\n",
    "            gaussian_nan,\n",
    "            occp.chunk({bdim: -1}),\n",
    "            input_core_dims=[[bdim]],\n",
    "            output_core_dims=[[bdim]],\n",
    "            vectorize=True,\n",
    "            dask=\"parallelized\",\n",
    "            kwargs={\"sigma\": sigma},\n",
    "            output_dtypes=[occp.dtype],\n",
    "        )\n",
    "    return occp\n",
    "\n",
    "\n",
    "def compute_si(fr: xr.DataArray, occp: xr.DataArray, agg_dim=\"x_bins\") -> xr.DataArray:\n",
    "    \"\"\"compute spatial information using binned firing rates and occupancy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fr : xr.DataArray\n",
    "        input firing rates\n",
    "    occp : xr.DataArray\n",
    "        input occupancy\n",
    "    agg_dim : str, optional\n",
    "        the dimension along which to aggreagate, by default \"x_bins\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        output spatial information\n",
    "    \"\"\"\n",
    "    mfr = fr.mean(agg_dim)\n",
    "    return (occp * fr / mfr * np.log2(fr / mfr, where=fr != 0)).sum(agg_dim)\n",
    "\n",
    "\n",
    "def compute_stb(S: xr.DataArray, **kwargs) -> xr.DataArray:\n",
    "    tmax = np.max(S.coords[\"trial\"])\n",
    "    fr_odd = compute_fr(S.sel(frame=(S.coords[\"trial\"] % 2 == 1)), **kwargs)\n",
    "    fr_even = compute_fr(S.sel(frame=(S.coords[\"trial\"] % 2 == 0)), **kwargs)\n",
    "    fr_first = compute_fr(S.sel(frame=(S.coords[\"trial\"] < tmax / 2)), **kwargs)\n",
    "    fr_last = compute_fr(S.sel(frame=(S.coords[\"trial\"] > tmax / 2)), **kwargs)\n",
    "    z_oe = compute_corr(fr_odd, fr_even)\n",
    "    z_fl = compute_corr(fr_first, fr_last)\n",
    "    return (z_fl + z_oe) / 2\n",
    "\n",
    "\n",
    "def compute_corr(fr1: xr.DataArray, fr2: xr.DataArray) -> xr.DataArray:\n",
    "    m1, m2 = fr1.mean(\"x_bins\"), fr2.mean(\"x_bins\")\n",
    "    s1, s2 = fr1.std(\"x_bins\"), fr2.std(\"x_bins\")\n",
    "    r = ((fr1 - m1) * (fr2 - m2)).mean(\"x_bins\") / (s1 * s2)\n",
    "    return np.arctanh(r)\n",
    "\n",
    "\n",
    "def thres_gmm(a: xr.DataArray, com=-1) -> xr.DataArray:\n",
    "    \"\"\"binnarize input array using gaussian mixture model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a : xr.DataArray\n",
    "        input array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        binnarized array\n",
    "    \"\"\"\n",
    "    a = a.reshape(-1, 1)\n",
    "    gmm = GaussianMixture(n_components=2)\n",
    "    gmm.fit(a)\n",
    "    idg = np.argsort(gmm.means_.reshape(-1))[com]\n",
    "    return (gmm.predict(a) == idg).reshape(-1)\n",
    "\n",
    "\n",
    "def thres_psize(fr: xr.DataArray, qthres: float, sz_thres: int) -> bool:\n",
    "    \"\"\"return whether a cell is place cell based on the place field size criteria:\n",
    "    the place field is defined as the longest continuous region where the averaged\n",
    "    firing rate in that region exceeds `qthres` percentile of all firing rates,\n",
    "    and then the place field must be larger than `sz_thres` spatial bins for a cell\n",
    "    to be classified as place cell.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fr : xr.DataArray\n",
    "        input firing rate of a cell\n",
    "    qthres : float\n",
    "        quantile threshold to define place field\n",
    "    sz_thres : int\n",
    "        threshold for size of place field\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        whether a cell is a place cell\n",
    "    \"\"\"\n",
    "    q = np.nanquantile(fr, qthres)\n",
    "    lab, nlab = label(fr > q)\n",
    "    if nlab:\n",
    "        len_ls = [np.sum(lab == lb + 1) for lb in range(nlab)]\n",
    "        if max(len_ls) > sz_thres:\n",
    "            max_lb = np.argmax(len_ls)\n",
    "            com = np.mean(np.where(lab == max_lb + 1)[0])\n",
    "            return com\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "\n",
    "def process_place(\n",
    "    dpath: str, nbins=200, nshuf=1000, sig_thres=0.95, sz_qthres=0.95, sz_thres=2\n",
    ") -> xr.Dataset:\n",
    "    try:\n",
    "        ts = pd.read_csv(os.path.join(dpath, \"timestamp.dat\"), delimiter=\"\\t\")\n",
    "        behav = (\n",
    "            pd.read_csv(os.path.join(dpath, \"behavConcat_LocationOutput.csv\"))[\n",
    "                [\"X\", \"Y\", \"Distance_px\"]\n",
    "            ]\n",
    "            .reset_index(drop=True)\n",
    "            .rename_axis(\"fmCam1\")\n",
    "            .reset_index()\n",
    "        )\n",
    "        minian_ds = open_minian(dpath, backend=\"zarr\")\n",
    "        print(\"processing {}\".format(dpath))\n",
    "    except:\n",
    "        print(\"file missing under {}\".format(dpath))\n",
    "        return xr.Dataset()\n",
    "    S = minian_ds[\"S\"].chunk({\"frame\": -1})\n",
    "    behav = process_behav(behav)\n",
    "    fmap = map_ts(ts)\n",
    "    fmap = fmap.merge(behav, how=\"left\", on=\"fmCam1\").set_index(\"fmCam0\")\n",
    "    try:\n",
    "        S = S.assign_coords(\n",
    "            x=(\"frame\", fmap[\"X\"][S.coords[\"frame\"].values]),\n",
    "            trial=(\"frame\", fmap[\"trial\"][S.coords[\"frame\"].values]),\n",
    "        )\n",
    "    except KeyError:\n",
    "        print(\"behavior mapping error, check timestamp file\")\n",
    "        return xr.Dataset()\n",
    "    # S_thres = (\n",
    "    #     xr.apply_ufunc(\n",
    "    #         thres_gmm,\n",
    "    #         S,\n",
    "    #         input_core_dims=[[\"frame\"]],\n",
    "    #         output_core_dims=[[\"frame\"]],\n",
    "    #         vectorize=True,\n",
    "    #         dask=\"parallelized\",\n",
    "    #         output_dtypes=[bool],\n",
    "    #     )\n",
    "    #     .rename(\"S_thres\")\n",
    "    #     .persist()\n",
    "    # )\n",
    "    S_thres = S\n",
    "    fr = compute_fr(S_thres, nbins=nbins).compute().rename(\"fr\")\n",
    "    stb = compute_stb(S_thres, nbins=nbins).compute().rename(\"stb\")\n",
    "    occp = compute_occp(S_thres, nbins=nbins).compute().rename(\"occp\")\n",
    "    si = compute_si(fr, occp).compute().rename(\"si\")\n",
    "    sh_ls = []\n",
    "    for sh in np.random.random_integers(0, S_thres.sizes[\"frame\"], nshuf):\n",
    "        S_sh = S_thres.roll(frame=sh, roll_coords=False)\n",
    "        sh_ls.append(S_sh)\n",
    "    S_shuf = xr.concat(sh_ls, \"shuf\").chunk({\"shuf\": \"auto\"})\n",
    "    fr_shuf = compute_fr(S_shuf, nbins=nbins).compute()\n",
    "    si_shuf = compute_si(fr_shuf, occp).compute()\n",
    "    stb_shuf = compute_stb(S_shuf, nbins=nbins).compute()\n",
    "    mask_si = (si > si_shuf.quantile(sig_thres, \"shuf\")).rename(\"mask_si\")\n",
    "    mask_stb = (stb > stb_shuf.quantile(sig_thres, \"shuf\")).rename(\"mask_stb\")\n",
    "    maxpos = xr.apply_ufunc(\n",
    "        thres_psize,\n",
    "        fr,\n",
    "        input_core_dims=[[\"x_bins\"]],\n",
    "        output_core_dims=[[]],\n",
    "        vectorize=True,\n",
    "        kwargs={\"qthres\": sz_qthres, \"sz_thres\": sz_thres},\n",
    "    ).rename(\"maxpos\")\n",
    "    return xr.merge([S_thres, fr, occp, si, mask_si, stb, mask_stb, maxpos])\n",
    "\n",
    "\n",
    "def vec_corr(fr0: xr.DataArray, fr1: xr.DataArray, agg_dim=\"x_bins\", vec_dim=\"index\"):\n",
    "    mask = fr0.notnull().all(vec_dim) & fr1.notnull().all(vec_dim)\n",
    "    fr0, fr1 = fr0.where(mask), fr1.where(mask)\n",
    "    fr0_mean = fr0.mean(agg_dim)\n",
    "    fr1_mean = fr1.mean(agg_dim)\n",
    "    fr0_var = ((fr0 - fr0_mean) ** 2).sum(agg_dim)\n",
    "    fr1_var = ((fr1 - fr1_mean) ** 2).sum(agg_dim)\n",
    "    return ((fr0 - fr0_mean) * (fr1 - fr1_mean)).sum(agg_dim) / np.sqrt(\n",
    "        fr0_var * fr1_var\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file missing under ./data/pfd2\n",
      "file missing under ./data/pfd2/ts44-3\n",
      "file missing under ./data/pfd2/ts44-3/.ipynb_checkpoints\n",
      "processing ./data/pfd2/ts44-3/s10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43544 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43624 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43684 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43774 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43816 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43920 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43878 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44068 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:44142 remote=tcp://127.0.0.1:42517>\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 14% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 15% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 18% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 19% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 17% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:50654 remote=tcp://127.0.0.1:42517>\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 16% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts44-3/s11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13494 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts44-3/s12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13492 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts44-3/s13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file missing under ./data/pfd2/ts45-4\n",
      "processing ./data/pfd2/ts45-4/s10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts45-4/s11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13492 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:42004 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:42024 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:42094 remote=tcp://127.0.0.1:42517>\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts45-4/s12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13492 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts45-4/s13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43286 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:43318 remote=tcp://127.0.0.1:42517>\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file missing under ./data/pfd2/ts46-1\n",
      "processing ./data/pfd2/ts46-1/s10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:53910 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:53946 remote=tcp://127.0.0.1:42517>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP  local=tcp://127.0.0.1:54012 remote=tcp://127.0.0.1:42517>\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts46-1/s11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13492 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts46-1/s12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 192\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 191\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ./data/pfd2/ts46-1/s13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/pandas/core/series.py:1143: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:337: DeprecationWarning: This function is deprecated. Please call randint(0, 13493 + 1) instead\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/dask/array/core.py:3118: PerformanceWarning: Increasing number of chunks by factor of 190\n",
      "  **blockwise_kwargs)\n",
      "/opt/miniconda3/envs/minian-dev/lib/python3.6/site-packages/ipykernel_launcher.py:277: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:   (animal: 3, frame: 13494, session: 4, unit_id: 720, x_bins: 200)\n",
      "Coordinates:\n",
      "    quantile  float64 0.95\n",
      "  * session   (session) object 's10' 's11' 's12' 's13'\n",
      "  * frame     (frame) int64 0 2 4 6 8 10 ... 26976 26978 26980 26982 26984 26986\n",
      "  * x_bins    (x_bins) int64 0 1 2 3 4 5 6 7 ... 192 193 194 195 196 197 198 199\n",
      "  * unit_id   (unit_id) int64 0 1 2 3 4 5 6 7 ... 714 715 717 718 720 721 722\n",
      "  * animal    (animal) object 'ts44-3' 'ts45-4' 'ts46-1'\n",
      "    trial     (animal, session, frame) float64 nan nan nan nan ... nan nan nan\n",
      "    x         (animal, session, frame) float64 nan nan nan nan ... nan nan nan\n",
      "Data variables:\n",
      "    S         (animal, session, unit_id, frame) float64 dask.array<chunksize=(1, 1, 720, 13494), meta=np.ndarray>\n",
      "    fr        (animal, session, unit_id, x_bins) float64 0.2266 0.2227 ... nan\n",
      "    occp      (animal, session, x_bins) float64 0.01059 0.0103 ... 0.01247\n",
      "    si        (animal, session, unit_id) float64 1.289 2.361 1.957 ... nan nan\n",
      "    mask_si   (animal, session, unit_id) float64 0.0 0.0 1.0 0.0 ... nan nan nan\n",
      "    stb       (animal, session, unit_id) float64 0.3447 0.3018 ... nan nan\n",
      "    mask_stb  (animal, session, unit_id) float64 0.0 0.0 0.0 0.0 ... nan nan nan\n",
      "    maxpos    (animal, session, unit_id) float64 36.0 33.0 105.5 ... nan nan nan\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dpath = \"./data/pfd2\"\n",
    "    cluster = LocalCluster(dashboard_address=\"0.0.0.0:9999\")\n",
    "    client = Client(cluster)\n",
    "    ds_ls = []\n",
    "    for root, dirs, files in os.walk(dpath):\n",
    "        if root.count(os.path.sep) > (dpath.count(os.path.sep) + 2):\n",
    "            continue\n",
    "        ds = process_place(root, nshuf=1000)\n",
    "        ds_ls.append(ds)\n",
    "    plc_ds = xrconcat_recursive(list(filter(bool, ds_ls)), [\"animal\", \"session\"])\n",
    "    print(plc_ds)\n",
    "    plc_ds.to_netcdf(\"./data/inter/place_cells.nc\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian-dev",
   "language": "python",
   "name": "minian-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
